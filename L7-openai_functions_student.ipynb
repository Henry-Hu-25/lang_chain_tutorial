{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3df44d6-62d0-4324-8052-419503a6b040",
   "metadata": {},
   "source": [
    "# OpenAI Function Calling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b038f2-759a-42e9-ab02-eca264b93ee5",
   "metadata": {},
   "source": [
    "**Notes**:\n",
    "- LLMs don't always produce the same results. The results you see in this notebook may differ from the results you see in the video.\n",
    "- Notebooks results are temporary. Download the notebooks to your local machine if you wish to save your results.\n",
    "- OpenAI has announced the release of an updated GPT-3.5-Turbo model and the deprecation of the ```gpt-3.5-turbo-0613``` model. The gpt-3.5-turbo-0613 model, which has been utilized in this Short Course since its launch in October 2023, will be replaced by the ```gpt-3.5-turbo``` model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a25d3f",
   "metadata": {},
   "source": [
    "**Takeaway**:\n",
    "- openai.ChatCompletion.create() is deprecated. Use client = OpenAI() and client.chat.completions.create() instead.\n",
    "- you can force the model to call a function by using the `function_call` parameter.\n",
    "- when taking a function call, the model will return a `response_message` object with empty content but non-empty `response_message.function_call.arguments`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d1a7aac-599c-4653-b497-49fe9a31a07d",
   "metadata": {
    "height": 115,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e036b435-e842-40a3-8e1c-1d5d716394c6",
   "metadata": {
    "height": 234
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Example dummy function hard coded to return the same weather\n",
    "# In production, this could be your backend API or an external API\n",
    "def get_current_weather(location, unit=\"fahrenheit\"):\n",
    "    \"\"\"Get the current weather in a given location\"\"\"\n",
    "    weather_info = {\n",
    "        \"location\": location,\n",
    "        \"temperature\": \"72\",\n",
    "        \"unit\": unit,\n",
    "        \"forecast\": [\"sunny\", \"windy\"],\n",
    "    }\n",
    "    # json.dumps converts a Python object to a JSON-formatted string.\n",
    "    return json.dumps(weather_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "290fae11-d9af-40f8-9b78-3d6a847737b2",
   "metadata": {
    "height": 319
   },
   "outputs": [],
   "source": [
    "# define a function\n",
    "functions = [\n",
    "    {\n",
    "        \"name\": \"get_current_weather\",\n",
    "        \"description\": \"Get the current weather in a given location\", # Description is counted as tokens\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The city and state, e.g. San Francisco, CA\", # Description is counted as tokens\n",
    "                },\n",
    "                \"unit\": {\"type\": \"string\", \"enum\": [\"celsius\", \"fahrenheit\"]},\n",
    "            },\n",
    "            \"required\": [\"location\"],\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b5e2abe-7cf0-4b00-8c08-b3df91d78eaa",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What's the weather like in Boston?\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58cc98f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /opt/homebrew/anaconda3/lib/python3.10/site-packages (1.97.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from openai) (0.6.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from openai) (2.11.7)\n",
      "Requirement already satisfied: sniffio in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from openai) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from openai) (4.13.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
      "Requirement already satisfied: certifi in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/homebrew/anaconda3/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "654fce05-7ef6-49d7-8d78-f190ecf3f0dd",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d8e837",
   "metadata": {},
   "source": [
    "> Note: This notebook was updated in June 2024. Consequently, we are now using the ```gpt-3.5-turbo model``` instead of the ```gpt-3.5-turbo-0613``` model featured by the instructor in the video lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa6385a-db38-40fa-b2b8-6fa226913c46",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "# Call the ChatCompletion endpoint - OUTDATED\n",
    "# response = openai.ChatCompletion.create(\n",
    "#     # OpenAI Updates: As of June 2024, we are now using the GPT-3.5-Turbo model\n",
    "#     model=\"gpt-3.5-turbo\",\n",
    "#     messages=messages,\n",
    "#     functions=functions\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12c8acd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62bf7bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions. create(\n",
    "    model = \"gpt-4.1\",\n",
    "    messages = messages,\n",
    "    functions = functions\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e66b83b",
   "metadata": {},
   "source": [
    "> Note: The following result may differ slightly from the one shown by the instructor in the video lesson due to the model being updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e341605-5e3e-44d1-b64e-79c121aeb8d8",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-C1UQLtCl7xsi2OgAmjOr201BBXkY5', choices=[Choice(finish_reason='function_call', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=FunctionCall(arguments='{\"location\":\"Boston, MA\",\"unit\":\"fahrenheit\"}', name='get_current_weather'), tool_calls=None))], created=1754471313, model='gpt-4.1-2025-04-14', object='chat.completion', service_tier='default', system_fingerprint='fp_51e1070cf2', usage=CompletionUsage(completion_tokens=22, prompt_tokens=79, total_tokens=101, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5748f7ce-9c74-435f-b5dc-d04e627675e3",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "response_message = response.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a7f733bd-e75b-4a84-9cbe-1a8c695015a3",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=FunctionCall(arguments='{\"location\":\"Boston, MA\",\"unit\":\"fahrenheit\"}', name='get_current_weather'), tool_calls=None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d8fa467-d9b3-4d62-b067-f6e8788b2907",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "response_message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d58d13f4-d131-4f70-8b68-dca7be2073e2",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FunctionCall(arguments='{\"location\":\"Boston, MA\",\"unit\":\"fahrenheit\"}', name='get_current_weather')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_message.function_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8b762467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"location\":\"Boston, MA\",\"unit\":\"fahrenheit\"}'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_message.function_call.arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "433a51b6-9c92-4765-85aa-285dccf7748b",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'location': 'Boston, MA', 'unit': 'fahrenheit'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# json.loads is a Python function that parses a JSON-formatted string and returns the corresponding Python object (e.g., dict)\n",
    "json.loads(response_message.function_call.arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "675d9372-4388-4f18-b44c-e291668ea46d",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "args = json.loads(response_message.function_call.arguments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3cbb1aec-454a-4a34-9a6b-351ee3759a3a",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"location\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}, \"temperature\": \"72\", \"unit\": \"fahrenheit\", \"forecast\": [\"sunny\", \"windy\"]}'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_current_weather(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3774d311",
   "metadata": {},
   "source": [
    "* Pass a message that is not related to a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8c2cbe66-784a-40ff-a268-7bd0f984d5b8",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"hi!\",\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3d7378",
   "metadata": {},
   "source": [
    "> Note: This notebook was updated in June 2024. Consequently, we are now using the ```gpt-3.5-turbo model``` instead of the ```gpt-3.5-turbo-0613``` model featured by the instructor in the video lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8300232d-4f02-478b-bba2-d47173422866",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "# response = openai.ChatCompletion.create(\n",
    "#     # OpenAI Updates: As of June 2024, we are now using the GPT-3.5-Turbo model\n",
    "#     model=\"gpt-3.5-turbo\",\n",
    "#     messages=messages,\n",
    "#     functions=functions,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4faf9a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model = \"gpt-4.1\",\n",
    "    messages = messages,\n",
    "    functions = functions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3e35564e-8f66-4b06-b14a-03e24a202a47",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-C1UVpoWJAtOR07XAN7P93TgF6fP95', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Hello! How can I help you today? ðŸ˜Š', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1754471653, model='gpt-4.1-2025-04-14', object='chat.completion', service_tier='default', system_fingerprint='fp_799e4ca3f1', usage=CompletionUsage(completion_tokens=11, prompt_tokens=74, total_tokens=85, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7aae46",
   "metadata": {},
   "source": [
    "* Pass additional parameters to force the model to use or not a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e2af9f72-1cb9-4a97-b030-22562ecab99d",
   "metadata": {
    "height": 251
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-C1UWvlSVls2mCe28hkTtUcfcE5t6q', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Hello! How can I help you today? ðŸ˜Š', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1754471721, model='gpt-4.1-2025-04-14', object='chat.completion', service_tier='default', system_fingerprint='fp_51e1070cf2', usage=CompletionUsage(completion_tokens=11, prompt_tokens=74, total_tokens=85, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"hi!\",\n",
    "    }\n",
    "]\n",
    "# response = openai.ChatCompletion.create(\n",
    "#     # OpenAI Updates: As of June 2024, we are now using the GPT-3.5-Turbo model\n",
    "#     model=\"gpt-3.5-turbo\",\n",
    "#     messages=messages,\n",
    "#     functions=functions,\n",
    "#     function_call=\"auto\",\n",
    "# )\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model = \"gpt-4.1\",\n",
    "    messages = messages,\n",
    "    functions = functions,\n",
    "    function_call = 'auto'\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284088e9",
   "metadata": {},
   "source": [
    "* Use mode 'none' for function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6ba8cafc-f785-4595-9e3c-48b06424ee8b",
   "metadata": {
    "height": 251
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-C1UXlgOdBYwMcPN1RSijvqGK75rnX', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Hello! How can I help you today? ðŸ˜Š', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1754471773, model='gpt-4.1-2025-04-14', object='chat.completion', service_tier='default', system_fingerprint='fp_799e4ca3f1', usage=CompletionUsage(completion_tokens=10, prompt_tokens=75, total_tokens=85, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"hi!\",\n",
    "    }\n",
    "]\n",
    "# response = openai.ChatCompletion.create(\n",
    "#     # OpenAI Updates: As of June 2024, we are now using the GPT-3.5-Turbo model\n",
    "#     model=\"gpt-3.5-turbo\",\n",
    "#     messages=messages,\n",
    "#     functions=functions,\n",
    "#     function_call=\"none\",\n",
    "# )\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model = \"gpt-4.1\",\n",
    "    messages = messages,\n",
    "    functions = functions,\n",
    "    function_call = 'none'\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae05a76e",
   "metadata": {},
   "source": [
    "* When the message should call a function and still uses mode 'none'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ca7cc5a7-1572-4171-9016-9ec2871d389b",
   "metadata": {
    "height": 251
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-C1UY4MlwjADhMj7MzQIAaCJT49IqF', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Let me check the current weather in Boston for you.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1754471792, model='gpt-4.1-2025-04-14', object='chat.completion', service_tier='default', system_fingerprint='fp_b3f1157249', usage=CompletionUsage(completion_tokens=11, prompt_tokens=79, total_tokens=90, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What's the weather in Boston?\",\n",
    "    }\n",
    "]\n",
    "# response = openai.ChatCompletion.create(\n",
    "#     # OpenAI Updates: As of June 2024, we are now using the GPT-3.5-Turbo model\n",
    "#     model=\"gpt-3.5-turbo\",\n",
    "#     messages=messages,\n",
    "#     functions=functions,\n",
    "#     function_call=\"none\",\n",
    "# )\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model = \"gpt-4.1\",\n",
    "    messages = messages,\n",
    "    functions = functions,\n",
    "    function_call = 'none'\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38735d9f",
   "metadata": {},
   "source": [
    "* Force calling a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "282a92ba-5677-4c72-b556-d29e6a4152a0",
   "metadata": {
    "height": 251
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-C1UYRMqUpvgVq929HM8wRTJDkxAKU', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=FunctionCall(arguments='{\"location\":\"San Francisco, CA\"}', name='get_current_weather'), tool_calls=None))], created=1754471815, model='gpt-4.1-2025-04-14', object='chat.completion', service_tier='default', system_fingerprint='fp_b3f1157249', usage=CompletionUsage(completion_tokens=8, prompt_tokens=84, total_tokens=92, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"hi!\",\n",
    "    }\n",
    "]\n",
    "# response = openai.ChatCompletion.create(\n",
    "#     # OpenAI Updates: As of June 2024, we are now using the GPT-3.5-Turbo model\n",
    "#     model=\"gpt-3.5-turbo\",\n",
    "#     messages=messages,\n",
    "#     functions=functions,\n",
    "#     function_call={\"name\": \"get_current_weather\"},\n",
    "# )\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model = \"gpt-4.1\",\n",
    "    messages = messages,\n",
    "    functions = functions,\n",
    "    function_call={\"name\": \"get_current_weather\"}\n",
    ")\n",
    "\n",
    "# The model just hallucinates (come up with a random location)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27abbdc",
   "metadata": {},
   "source": [
    "* Final notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3c5229a4-2700-48b4-b2b9-3b1e1535f903",
   "metadata": {
    "height": 251
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-C1Ucim3gI5SnQ8a0ZKm9yw92iNyN9', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=FunctionCall(arguments='{\"location\":\"Boston, MA\",\"unit\":\"fahrenheit\"}', name='get_current_weather'), tool_calls=None))], created=1754472080, model='gpt-4.1-2025-04-14', object='chat.completion', service_tier='default', system_fingerprint='fp_b3f1157249', usage=CompletionUsage(completion_tokens=12, prompt_tokens=89, total_tokens=101, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"What's the weather like in Boston!\",\n",
    "    }\n",
    "]\n",
    "# response = openai.ChatCompletion.create(\n",
    "#     # OpenAI Updates: As of June 2024, we are now using the GPT-3.5-Turbo model\n",
    "#     model=\"gpt-3.5-turbo\",\n",
    "#     messages=messages,\n",
    "#     functions=functions,\n",
    "#     function_call={\"name\": \"get_current_weather\"},\n",
    "# )\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model = \"gpt-4.1\",\n",
    "    messages=messages,\n",
    "    functions=functions,\n",
    "    function_call={\"name\": \"get_current_weather\"}\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e2f3a9d7-9f30-4524-a952-5dd87c6d2eef",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "# messages.append(response[\"choices\"][0][\"message\"])\n",
    "messages.append(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c817376f-3a7f-4448-acdd-1639c70d42e4",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"location\": {\"location\": \"Boston, MA\", \"unit\": \"fahrenheit\"}, \"temperature\": \"72\", \"unit\": \"fahrenheit\", \"forecast\": [\"sunny\", \"windy\"]}'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = json.loads(response.choices[0].message.function_call.arguments)\n",
    "observation = get_current_weather(args)\n",
    "observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "63454808-10a2-4301-9977-89aa79018152",
   "metadata": {
    "height": 132
   },
   "outputs": [],
   "source": [
    "messages.append(\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": \"get_current_weather\",\n",
    "            \"content\": observation,\n",
    "        }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f323fb69-c907-4f19-a2d9-80d828b4a5c2",
   "metadata": {
    "height": 98
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Right now in Boston, it's 72Â°F, sunny, and windy! If youâ€™re heading outside, you might want to bring a light jacket just in case the wind picks up. Let me know if you need a more detailed forecast or info for another day!\n"
     ]
    }
   ],
   "source": [
    "# response = openai.ChatCompletion.create(\n",
    "#     model=\"gpt-3.5-turbo\",\n",
    "#     messages=messages,\n",
    "# )\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model = \"gpt-4.1\",\n",
    "    messages = messages,\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
