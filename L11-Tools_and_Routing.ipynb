{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b815ef73",
   "metadata": {},
   "source": [
    "# Tools and Routing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decf0e7b",
   "metadata": {},
   "source": [
    "**Takeaways**\n",
    "- Differnet ways of converting objects into OpenAI functions\n",
    "    - Pydantic object: convert_pydantic_to_openai_function(Class)\n",
    "    - Functions (with Pydantic schema): format_tool_to_openai_function\n",
    "    - OpenApi_spec: openapi_spec_to_openai_fn\n",
    "- Without Pydantic schema, the function will be called with the arguments as a dictionary (e.g. search_wikipedia({\"query\": \"langchain\"}))\n",
    "- Use OpenAIFunctionsAgentOutputParser to route between an a function call and str output, which can be printed out using a \"route\" helper function\n",
    "- Use \"from langchain_openai import ChatOpenAI\" to replace \"from langchain.chat_models import ChatOpenAI\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb41f5f4-df8d-4d04-9eaa-193b8c29b00b",
   "metadata": {
    "height": 115,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "139c45e6-65a4-4fcb-a109-e5ba41a80835",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "from langchain.agents import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a17f623-9342-46bd-a913-9ea6be32a7a9",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "@tool\n",
    "def search(query: str) -> str:\n",
    "    \"\"\"Search for weather online\"\"\"\n",
    "    return \"42f\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db510949-acb8-4f69-b6c9-242b84fdc63a",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('search',\n",
       " 'Search for weather online',\n",
       " {'query': {'title': 'Query', 'type': 'string'}})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.name, search.description, search.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8765af16-17fc-4490-98ab-4e9dd59337cf",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "class SearchInput(BaseModel):\n",
    "    query: str = Field(description=\"Thing to search for\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91d20261-e18f-4989-808c-c4f36643d024",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "# Once a tool decorator is added, the function becomes a Langchain tool object\n",
    "@tool(args_schema=SearchInput)\n",
    "def search(query: str) -> str:\n",
    "    \"\"\"Search for the weather online.\"\"\"\n",
    "    return \"42f\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "060dc15b-f95f-47ab-b081-d6736f277ebc",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dp/j76v96ld7kgfdxz859wprxkw0000gn/T/ipykernel_46420/2822380983.py:2: LangChainDeprecationWarning: The method `BaseTool.__call__` was deprecated in langchain-core 0.1.47 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  search(\"sf\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'42f'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.run(\"sf\")\n",
    "search(\"sf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e93b85b2-1786-4f63-8e65-cd6a8b5c0b33",
   "metadata": {
    "height": 676
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from pydantic import BaseModel, Field\n",
    "import datetime\n",
    "\n",
    "# Define the input schema\n",
    "class OpenMeteoInput(BaseModel):\n",
    "    # ... means latitude is required\n",
    "    latitude: float = Field(..., description=\"Latitude of the location to fetch weather data for\")\n",
    "    longitude: float = Field(..., description=\"Longitude of the location to fetch weather data for\")\n",
    "\n",
    "@tool(args_schema=OpenMeteoInput)\n",
    "def get_current_temperature(latitude: float, longitude: float) -> dict:\n",
    "    \"\"\"Fetch current temperature for given coordinates.\"\"\"\n",
    "    \n",
    "    BASE_URL = \"https://api.open-meteo.com/v1/forecast\"\n",
    "    \n",
    "    # Parameters for the request\n",
    "    params = {\n",
    "        'latitude': latitude,\n",
    "        'longitude': longitude,\n",
    "        'hourly': 'temperature_2m',\n",
    "        'forecast_days': 1,\n",
    "    }\n",
    "\n",
    "    # Make the request\n",
    "    response = requests.get(BASE_URL, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        results = response.json()\n",
    "        print(results)\n",
    "    else:\n",
    "        raise Exception(f\"API Request failed with status code: {response.status_code}\")\n",
    "\n",
    "    current_utc_time = datetime.datetime.utcnow()\n",
    "    time_list = [datetime.datetime.fromisoformat(time_str.replace('Z', '+00:00')) for time_str in results['hourly']['time']]\n",
    "    temperature_list = results['hourly']['temperature_2m']\n",
    "    \n",
    "    closest_time_index = min(range(len(time_list)), key=lambda i: abs(time_list[i] - current_utc_time))\n",
    "    current_temperature = temperature_list[closest_time_index]\n",
    "    \n",
    "    return f'The current temperature is {current_temperature}°C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "731ed353-a27d-42df-89a8-9767bafb23be",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('get_current_temperature',\n",
       " 'Fetch current temperature for given coordinates.',\n",
       " {'latitude': {'description': 'Latitude of the location to fetch weather data for',\n",
       "   'title': 'Latitude',\n",
       "   'type': 'number'},\n",
       "  'longitude': {'description': 'Longitude of the location to fetch weather data for',\n",
       "   'title': 'Longitude',\n",
       "   'type': 'number'}})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_current_temperature.name, get_current_temperature.description, get_current_temperature.args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36aacbec-9cdd-414a-b502-168cea350a30",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "from langchain.tools.render import format_tool_to_openai_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6277b6a8-f197-4057-a96a-5ebb61e18520",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dp/j76v96ld7kgfdxz859wprxkw0000gn/T/ipykernel_46420/540789164.py:1: LangChainDeprecationWarning: The function `_format_tool_to_openai_function` was deprecated in LangChain 0.1.16 and will be removed in 1.0. Use :meth:`~langchain_core.utils.function_calling.convert_to_openai_function()` instead.\n",
      "  format_tool_to_openai_function(get_current_temperature)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'get_current_temperature',\n",
       " 'description': 'Fetch current temperature for given coordinates.',\n",
       " 'parameters': {'properties': {'latitude': {'description': 'Latitude of the location to fetch weather data for',\n",
       "    'type': 'number'},\n",
       "   'longitude': {'description': 'Longitude of the location to fetch weather data for',\n",
       "    'type': 'number'}},\n",
       "  'required': ['latitude', 'longitude'],\n",
       "  'type': 'object'}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_tool_to_openai_function(get_current_temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e088eceb-424b-4da6-981f-63322c9ac56a",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'latitude': 13.0, 'longitude': 14.0, 'generationtime_ms': 0.019669532775878906, 'utc_offset_seconds': 0, 'timezone': 'GMT', 'timezone_abbreviation': 'GMT', 'elevation': 280.0, 'hourly_units': {'time': 'iso8601', 'temperature_2m': '°C'}, 'hourly': {'time': ['2025-08-09T00:00', '2025-08-09T01:00', '2025-08-09T02:00', '2025-08-09T03:00', '2025-08-09T04:00', '2025-08-09T05:00', '2025-08-09T06:00', '2025-08-09T07:00', '2025-08-09T08:00', '2025-08-09T09:00', '2025-08-09T10:00', '2025-08-09T11:00', '2025-08-09T12:00', '2025-08-09T13:00', '2025-08-09T14:00', '2025-08-09T15:00', '2025-08-09T16:00', '2025-08-09T17:00', '2025-08-09T18:00', '2025-08-09T19:00', '2025-08-09T20:00', '2025-08-09T21:00', '2025-08-09T22:00', '2025-08-09T23:00'], 'temperature_2m': [26.8, 26.4, 26.0, 25.7, 25.4, 25.3, 25.6, 26.4, 27.8, 29.2, 30.5, 31.7, 32.4, 33.0, 33.0, 32.7, 31.8, 30.5, 29.6, 29.0, 28.1, 27.4, 27.0, 26.8]}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The current temperature is 26.4°C'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_current_temperature({\"latitude\": 13, \"longitude\": 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5eefc272-d205-4bad-ab00-282ccb3cc2fe",
   "metadata": {
    "height": 319
   },
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "@tool\n",
    "def search_wikipedia(query: str) -> str:\n",
    "    \"\"\"Run Wikipedia search and get page summaries.\"\"\"\n",
    "    page_titles = wikipedia.search(query)\n",
    "    summaries = []\n",
    "    for page_title in page_titles[: 3]:\n",
    "        try:\n",
    "            wiki_page =  wikipedia.page(title=page_title, auto_suggest=False)\n",
    "            summaries.append(f\"Page: {page_title}\\nSummary: {wiki_page.summary}\")\n",
    "        except (\n",
    "            self.wiki_client.exceptions.PageError,\n",
    "            self.wiki_client.exceptions.DisambiguationError,\n",
    "        ):\n",
    "            pass\n",
    "    if not summaries:\n",
    "        return \"No good Wikipedia Search Result was found\"\n",
    "    return \"\\n\\n\".join(summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "289c5d0c-0e71-4d70-963f-9d9f58e53d56",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('search_wikipedia', 'Run Wikipedia search and get page summaries.')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_wikipedia.name, search_wikipedia.description, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5b876cd-cc6c-484d-a3fa-d8810e22d564",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'search_wikipedia',\n",
       " 'description': 'Run Wikipedia search and get page summaries.',\n",
       " 'parameters': {'properties': {'query': {'type': 'string'}},\n",
       "  'required': ['query'],\n",
       "  'type': 'object'}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_tool_to_openai_function(search_wikipedia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6dfb10e9-5d1e-474a-9c8f-7abdf7939a34",
   "metadata": {
    "height": 30,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page: LangChain\n",
      "Summary: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\n",
      "\n",
      "Page: Vector database\n",
      "Summary: A vector database, vector store or vector search engine is a database that uses the vector space model to store vectors (fixed-length lists of numbers) along with other data items. Vector databases typically implement one or more approximate nearest neighbor algorithms, so that one can search the database with a query vector to retrieve the closest matching database records.\n",
      "Vectors are mathematical representations of data in a high-dimensional space. In this space, each dimension corresponds to a feature of the data, with the number of dimensions ranging from a few hundred to tens of thousands, depending on the complexity of the data being represented. A vector's position in this space represents its characteristics. Words, phrases, or entire documents, as well as images, audio, and other types of data, can all be vectorized.\n",
      "These feature vectors may be computed from the raw data using machine learning methods such as feature extraction algorithms, word embeddings or deep learning networks. The goal is that semantically similar data items receive feature vectors close to each other.\n",
      "Vector databases can be used for similarity search, semantic search, multi-modal search, recommendations engines, large language models (LLMs), object detection,  etc.\n",
      "Vector databases are also often used to implement retrieval-augmented generation (RAG), a method to improve domain-specific responses of large language models. The retrieval component of a RAG can be any search system, but is most often implemented as a vector database. Text documents describing the domain of interest are collected, and for each document or document section, a feature vector (known as an \"embedding\") is computed, typically using a deep learning network, and stored in a vector database. Given a user prompt, the feature vector of the prompt is computed, and the database is queried to retrieve the most relevant documents. These are then automatically added into the context window of the large language model, and the large language model proceeds to create a response to the prompt given this context.\n",
      "\n",
      "Page: Model Context Protocol\n",
      "Summary: The Model Context Protocol (MCP) is an open standard, open-source framework introduced by Anthropic in November 2024 to standardize the way artificial intelligence (AI) systems like large language models (LLMs) integrate and share data with external tools, systems, and data sources. MCP provides a universal interface for reading files, executing functions, and handling contextual prompts. Following its announcement, the protocol was adopted by major AI providers, including OpenAI and Google DeepMind.\n"
     ]
    }
   ],
   "source": [
    "print(search_wikipedia({\"query\": \"langchain\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "54cbe57e-f64c-4392-bcdd-9621fe1e46e5",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "from langchain.chains.openai_functions.openapi import openapi_spec_to_openai_fn\n",
    "# from langchain.utilities.openapi import OpenAPISpec\n",
    "from langchain_community.utilities.openapi import OpenAPISpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7fe38e50-874c-49bd-8681-f95dcab0b464",
   "metadata": {
    "height": 3090
   },
   "outputs": [],
   "source": [
    "# For conversion into LangChain-compatible functions using openapi_spec_to_openai_fn()\n",
    "# Openapi_spec\n",
    "\n",
    "text = \"\"\"\n",
    "{\n",
    "  \"openapi\": \"3.0.0\",\n",
    "  \"info\": {\n",
    "    \"version\": \"1.0.0\",\n",
    "    \"title\": \"Swagger Petstore\",\n",
    "    \"license\": {\n",
    "      \"name\": \"MIT\"\n",
    "    }\n",
    "  },\n",
    "  \"servers\": [\n",
    "    {\n",
    "      \"url\": \"http://petstore.swagger.io/v1\"\n",
    "    }\n",
    "  ],\n",
    "  \"paths\": {\n",
    "    \"/pets\": {\n",
    "      \"get\": {\n",
    "        \"summary\": \"List all pets\",\n",
    "        \"operationId\": \"listPets\",\n",
    "        \"tags\": [\n",
    "          \"pets\"\n",
    "        ],\n",
    "        \"parameters\": [\n",
    "          {\n",
    "            \"name\": \"limit\",\n",
    "            \"in\": \"query\",\n",
    "            \"description\": \"How many items to return at one time (max 100)\",\n",
    "            \"required\": false,\n",
    "            \"schema\": {\n",
    "              \"type\": \"integer\",\n",
    "              \"maximum\": 100,\n",
    "              \"format\": \"int32\"\n",
    "            }\n",
    "          }\n",
    "        ],\n",
    "        \"responses\": {\n",
    "          \"200\": {\n",
    "            \"description\": \"A paged array of pets\",\n",
    "            \"headers\": {\n",
    "              \"x-next\": {\n",
    "                \"description\": \"A link to the next page of responses\",\n",
    "                \"schema\": {\n",
    "                  \"type\": \"string\"\n",
    "                }\n",
    "              }\n",
    "            },\n",
    "            \"content\": {\n",
    "              \"application/json\": {\n",
    "                \"schema\": {\n",
    "                  \"$ref\": \"#/components/schemas/Pets\"\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "          },\n",
    "          \"default\": {\n",
    "            \"description\": \"unexpected error\",\n",
    "            \"content\": {\n",
    "              \"application/json\": {\n",
    "                \"schema\": {\n",
    "                  \"$ref\": \"#/components/schemas/Error\"\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      \"post\": {\n",
    "        \"summary\": \"Create a pet\",\n",
    "        \"operationId\": \"createPets\",\n",
    "        \"tags\": [\n",
    "          \"pets\"\n",
    "        ],\n",
    "        \"responses\": {\n",
    "          \"201\": {\n",
    "            \"description\": \"Null response\"\n",
    "          },\n",
    "          \"default\": {\n",
    "            \"description\": \"unexpected error\",\n",
    "            \"content\": {\n",
    "              \"application/json\": {\n",
    "                \"schema\": {\n",
    "                  \"$ref\": \"#/components/schemas/Error\"\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    },\n",
    "    \"/pets/{petId}\": {\n",
    "      \"get\": {\n",
    "        \"summary\": \"Info for a specific pet\",\n",
    "        \"operationId\": \"showPetById\",\n",
    "        \"tags\": [\n",
    "          \"pets\"\n",
    "        ],\n",
    "        \"parameters\": [\n",
    "          {\n",
    "            \"name\": \"petId\",\n",
    "            \"in\": \"path\",\n",
    "            \"required\": true,\n",
    "            \"description\": \"The id of the pet to retrieve\",\n",
    "            \"schema\": {\n",
    "              \"type\": \"string\"\n",
    "            }\n",
    "          }\n",
    "        ],\n",
    "        \"responses\": {\n",
    "          \"200\": {\n",
    "            \"description\": \"Expected response to a valid request\",\n",
    "            \"content\": {\n",
    "              \"application/json\": {\n",
    "                \"schema\": {\n",
    "                  \"$ref\": \"#/components/schemas/Pet\"\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "          },\n",
    "          \"default\": {\n",
    "            \"description\": \"unexpected error\",\n",
    "            \"content\": {\n",
    "              \"application/json\": {\n",
    "                \"schema\": {\n",
    "                  \"$ref\": \"#/components/schemas/Error\"\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"components\": {\n",
    "    \"schemas\": {\n",
    "      \"Pet\": {\n",
    "        \"type\": \"object\",\n",
    "        \"required\": [\n",
    "          \"id\",\n",
    "          \"name\"\n",
    "        ],\n",
    "        \"properties\": {\n",
    "          \"id\": {\n",
    "            \"type\": \"integer\",\n",
    "            \"format\": \"int64\"\n",
    "          },\n",
    "          \"name\": {\n",
    "            \"type\": \"string\"\n",
    "          },\n",
    "          \"tag\": {\n",
    "            \"type\": \"string\"\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      \"Pets\": {\n",
    "        \"type\": \"array\",\n",
    "        \"maxItems\": 100,\n",
    "        \"items\": {\n",
    "          \"$ref\": \"#/components/schemas/Pet\"\n",
    "        }\n",
    "      },\n",
    "      \"Error\": {\n",
    "        \"type\": \"object\",\n",
    "        \"required\": [\n",
    "          \"code\",\n",
    "          \"message\"\n",
    "        ],\n",
    "        \"properties\": {\n",
    "          \"code\": {\n",
    "            \"type\": \"integer\",\n",
    "            \"format\": \"int32\"\n",
    "          },\n",
    "          \"message\": {\n",
    "            \"type\": \"string\"\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "89f9f0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '''\n",
    "openapi: 3.0.0\n",
    "info:\n",
    "  version: 1.0.0\n",
    "  title: Swagger Petstore\n",
    "  license:\n",
    "    name: MIT\n",
    "servers:\n",
    "  - url: http://petstore.swagger.io/v1\n",
    "paths:\n",
    "  /pets:\n",
    "    get:\n",
    "      summary: List all pets\n",
    "      operationId: listPets\n",
    "      tags:\n",
    "        - pets\n",
    "      parameters:\n",
    "        - name: limit\n",
    "          in: query\n",
    "          description: How many items to return at one time (max 100)\n",
    "          required: false\n",
    "          schema:\n",
    "            type: integer\n",
    "            maximum: 100\n",
    "            format: int32\n",
    "      responses:\n",
    "        '200':\n",
    "          description: A paged array of pets\n",
    "          headers:\n",
    "            x-next:\n",
    "              description: A link to the next page of responses\n",
    "              schema:\n",
    "                type: string\n",
    "          content:\n",
    "            application/json:\n",
    "              schema:\n",
    "                $ref: '#/components/schemas/Pets'\n",
    "        default:\n",
    "          description: unexpected error\n",
    "          content:\n",
    "            application/json:\n",
    "              schema:\n",
    "                $ref: '#/components/schemas/Error'\n",
    "    post:\n",
    "      summary: Create a pet\n",
    "      operationId: createPets\n",
    "      tags:\n",
    "        - pets\n",
    "      responses:\n",
    "        '201':\n",
    "          description: Null response\n",
    "        default:\n",
    "          description: unexpected error\n",
    "          content:\n",
    "            application/json:\n",
    "              schema:\n",
    "                $ref: '#/components/schemas/Error'\n",
    "  /pets/{petId}:\n",
    "    get:\n",
    "      summary: Info for a specific pet\n",
    "      operationId: showPetById\n",
    "      tags:\n",
    "        - pets\n",
    "      parameters:\n",
    "        - name: petId\n",
    "          in: path\n",
    "          required: true\n",
    "          description: The id of the pet to retrieve\n",
    "          schema:\n",
    "            type: string\n",
    "      responses:\n",
    "        '200':\n",
    "          description: Expected response to a valid request\n",
    "          content:\n",
    "            application/json:\n",
    "              schema:\n",
    "                $ref: '#/components/schemas/Pet'\n",
    "        default:\n",
    "          description: unexpected error\n",
    "          content:\n",
    "            application/json:\n",
    "              schema:\n",
    "                $ref: '#/components/schemas/Error'\n",
    "components:\n",
    "  schemas:\n",
    "    Pet:\n",
    "      type: object\n",
    "      required:\n",
    "        - id\n",
    "        - name\n",
    "      properties:\n",
    "        id:\n",
    "          type: integer\n",
    "          format: int64\n",
    "        name:\n",
    "          type: string\n",
    "        tag:\n",
    "          type: string\n",
    "    Pets:\n",
    "      type: array\n",
    "      maxItems: 100\n",
    "      items:\n",
    "        $ref: '#/components/schemas/Pet'\n",
    "    Error:\n",
    "      type: object\n",
    "      required:\n",
    "        - code\n",
    "        - message\n",
    "      properties:\n",
    "        code:\n",
    "          type: integer\n",
    "          format: int32\n",
    "        message:\n",
    "          type: string\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "653156d4-d6a4-499b-aab3-cf4f7b1f0c47",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attempting to load an OpenAPI 3.0.0 spec.  This may result in degraded performance. Convert your OpenAPI spec to 3.1.* spec for better support.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'super' object has no attribute 'parse_obj'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m spec \u001b[38;5;241m=\u001b[39m \u001b[43mOpenAPISpec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/langchain_community/utilities/openapi.py:246\u001b[0m, in \u001b[0;36mOpenAPISpec.from_text\u001b[0;34m(cls, text)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m json\u001b[38;5;241m.\u001b[39mJSONDecodeError:\n\u001b[1;32m    245\u001b[0m     spec_dict \u001b[38;5;241m=\u001b[39m yaml\u001b[38;5;241m.\u001b[39msafe_load(text)\n\u001b[0;32m--> 246\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_spec_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/langchain_community/utilities/openapi.py:237\u001b[0m, in \u001b[0;36mOpenAPISpec.from_spec_dict\u001b[0;34m(cls, spec_dict)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_spec_dict\u001b[39m(\u001b[38;5;28mcls\u001b[39m, spec_dict: \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m OpenAPISpec:\n\u001b[1;32m    236\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get an OpenAPI spec from a dict.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 237\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_obj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.10/site-packages/langchain_community/utilities/openapi.py:221\u001b[0m, in \u001b[0;36mOpenAPISpec.parse_obj\u001b[0;34m(cls, obj)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_alert_unsupported_spec(obj)\n\u001b[0;32m--> 221\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_obj\u001b[49m(obj)\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ValidationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m# We are handling possibly misconfigured specs and\u001b[39;00m\n\u001b[1;32m    224\u001b[0m     \u001b[38;5;66;03m# want to do a best-effort job to get a reasonable interface out of it.\u001b[39;00m\n\u001b[1;32m    225\u001b[0m     new_obj \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(obj)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'super' object has no attribute 'parse_obj'"
     ]
    }
   ],
   "source": [
    "spec = OpenAPISpec.from_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d9ba6100-3c88-4b05-af93-784b57bf7424",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "pet_openai_functions, pet_callables = openapi_spec_to_openai_fn(spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "91199697-c662-438f-8c68-e6daa8aad07d",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{'name': 'listPets',\n",
       "   'description': 'List all pets',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'params': {'type': 'object',\n",
       "      'properties': {'limit': {'type': 'integer',\n",
       "        'maximum': 100.0,\n",
       "        'schema_format': 'int32',\n",
       "        'description': 'How many items to return at one time (max 100)'}},\n",
       "      'required': []}}}},\n",
       "  {'name': 'createPets',\n",
       "   'description': 'Create a pet',\n",
       "   'parameters': {'type': 'object', 'properties': {}}},\n",
       "  {'name': 'showPetById',\n",
       "   'description': 'Info for a specific pet',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'path_params': {'type': 'object',\n",
       "      'properties': {'petId': {'type': 'string',\n",
       "        'description': 'The id of the pet to retrieve'}},\n",
       "      'required': ['petId']}}}}],\n",
       " <function langchain.chains.openai_functions.openapi.openapi_spec_to_openai_fn.<locals>.default_call_api(name: 'str', fn_args: 'dict', headers: 'Optional[dict]' = None, params: 'Optional[dict]' = None, **kwargs: 'Any') -> 'Any'>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pet_openai_functions, pet_callables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9be336a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm sorry, but I don't have access to specific databases or records to provide information about a pet with a specific ID. If you have a specific context or details about the pet, I would be happy to help with general information or advice related to pets!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 51, 'prompt_tokens': 15, 'total_tokens': 66, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-C2Sc21x01tHrl8AapHTu0rfWJkesh', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--d0640089-e2a4-4bd8-bb79-3888a7dd1560-0', usage_metadata={'input_tokens': 15, 'output_tokens': 51, 'total_tokens': 66, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "resp = model.invoke(\"tell me about pet with id 42\")\n",
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ae8b3c1b-7a30-4b1b-abfd-e56f90b1d166",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "# from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ed100888-f3d4-4739-bba5-f839033850a3",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pet_openai_functions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m ChatOpenAI(temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4o-mini\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mbind(functions\u001b[38;5;241m=\u001b[39m\u001b[43mpet_openai_functions\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pet_openai_functions' is not defined"
     ]
    }
   ],
   "source": [
    "model = ChatOpenAI(temperature=0, model=\"gpt-4o-mini\").bind(functions=pet_openai_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4063cdea-627c-4cc1-a2b5-9b5b6dcf179e",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Here are three popular pet names:\\n\\n1. Bella\\n2. Max\\n3. Charlie\\n\\nThese names are commonly used for dogs and cats!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 29, 'prompt_tokens': 12, 'total_tokens': 41, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_34a54ae93c', 'id': 'chatcmpl-C2ScIpPZzMrf0WPdoiO7K5arE3bL9', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--9c205ce1-f39e-4bf1-b0c4-b1e188631306-0', usage_metadata={'input_tokens': 12, 'output_tokens': 29, 'total_tokens': 41, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"what are three pets names\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3a1f5534-cf06-4baf-b710-f169ea7434ac",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm sorry, but I don't have access to specific databases or records to look up information about a pet with ID 42. If you provide more context or details about the pet, I might be able to help you with general information or advice related to pets!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 52, 'prompt_tokens': 15, 'total_tokens': 67, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_62a23a81ef', 'id': 'chatcmpl-C2ScMSFyulRqKuBOpzBMN921jww1z', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--04985452-918d-42a5-8199-22e3fc78b6cc-0', usage_metadata={'input_tokens': 15, 'output_tokens': 52, 'total_tokens': 67, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"tell me about pet with id 42\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198b21dd-c9de-491d-9a0c-71ae56727689",
   "metadata": {},
   "source": [
    "### Routing\n",
    "\n",
    "In lesson 3, we show an example of function calling deciding between two candidate functions.\n",
    "\n",
    "Given our tools above, let's format these as OpenAI functions and show this same behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8137758c-c5d3-47df-9062-5e31d43657e7",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "functions = [\n",
    "    format_tool_to_openai_function(f) for f in [\n",
    "        search_wikipedia, get_current_temperature\n",
    "    ]\n",
    "]\n",
    "model = ChatOpenAI(temperature=0).bind(functions=functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "99120542-36bc-4ed1-aa9e-e2294e282c81",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"latitude\":37.7749,\"longitude\":-122.4194}', 'name': 'get_current_temperature'}}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 105, 'total_tokens': 130, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'function_call', 'logprobs': None}, id='run--dc00ed39-19b3-4844-a8e2-70f155033621-0')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"what is the weather in sf right now\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a20047d9-4b34-4e6c-9407-570af1559bc8",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"query\":\"Langchain\"}', 'name': 'search_wikipedia'}}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 101, 'total_tokens': 117, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'function_call', 'logprobs': None}, id='run--d492a385-0efd-41e2-b8a8-f338e05b968a-0')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"what is langchain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "831a0506-1d5c-4bc3-b67f-24e201a4fa6d",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are helpful but sassy assistant\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "])\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d9c32ccc-6691-4dd5-98dc-aabf02563ad5",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"latitude\":37.7749,\"longitude\":-122.4194}', 'name': 'get_current_temperature'}}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 113, 'total_tokens': 138, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'function_call', 'logprobs': None}, id='run--79750150-c04b-4b68-adcb-61670537436a-0')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"what is the weather in sf right now\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "921e808c-6618-4d2f-85df-1f3089497724",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "094baef1-4140-41f4-9111-ff9710826e6b",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "chain = prompt | model | OpenAIFunctionsAgentOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f105e8e8-d418-4d4a-95eb-52636d4e890f",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "result = chain.invoke({\"input\": \"what is the weather in sf right now\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "409b26c0-a1e0-4225-ae2e-396c1f76bf0a",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.agents.AgentActionMessageLog"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9cdde008-4b11-4ab2-a01c-6ae394a7dccf",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'get_current_temperature'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "66ffb308-3d77-4acb-b4b5-e2b0d38f3860",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'latitude': 37.7749, 'longitude': -122.4194}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.tool_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "07e661b1-6d0d-43b9-9de4-19c6cceff291",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'latitude': 37.763283, 'longitude': -122.41286, 'generationtime_ms': 0.026464462280273438, 'utc_offset_seconds': 0, 'timezone': 'GMT', 'timezone_abbreviation': 'GMT', 'elevation': 18.0, 'hourly_units': {'time': 'iso8601', 'temperature_2m': '°C'}, 'hourly': {'time': ['2025-08-09T00:00', '2025-08-09T01:00', '2025-08-09T02:00', '2025-08-09T03:00', '2025-08-09T04:00', '2025-08-09T05:00', '2025-08-09T06:00', '2025-08-09T07:00', '2025-08-09T08:00', '2025-08-09T09:00', '2025-08-09T10:00', '2025-08-09T11:00', '2025-08-09T12:00', '2025-08-09T13:00', '2025-08-09T14:00', '2025-08-09T15:00', '2025-08-09T16:00', '2025-08-09T17:00', '2025-08-09T18:00', '2025-08-09T19:00', '2025-08-09T20:00', '2025-08-09T21:00', '2025-08-09T22:00', '2025-08-09T23:00'], 'temperature_2m': [23.7, 21.9, 18.2, 16.3, 15.0, 14.8, 14.6, 14.3, 13.9, 13.9, 13.6, 13.3, 13.6, 13.5, 13.6, 14.5, 15.1, 16.7, 18.2, 22.5, 22.7, 22.0, 21.6, 20.9]}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The current temperature is 21.9°C'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_current_temperature(result.tool_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "057e3072-a203-4a5e-b1f6-b250cd7bd33b",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "result = chain.invoke({\"input\": \"hi!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5be6bc0f-5b81-49fa-ac16-b8896847d87a",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.agents.AgentFinish"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dd128d20-f552-4cc5-a45e-f47b58c9982b",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output': 'Well, hello there! How can I assist you today?'}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.return_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "134f422a-b72b-40df-9552-cf9f9fc2d780",
   "metadata": {
    "height": 183
   },
   "outputs": [],
   "source": [
    "from langchain.schema.agent import AgentFinish\n",
    "def route(result):\n",
    "    if isinstance(result, AgentFinish):\n",
    "        return result.return_values['output']\n",
    "    else:\n",
    "        tools = {\n",
    "            \"search_wikipedia\": search_wikipedia, \n",
    "            \"get_current_temperature\": get_current_temperature,\n",
    "        }\n",
    "        return tools[result.tool].run(result.tool_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8fefc329-b270-4ebb-b884-430e4e541e7f",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "chain = prompt | model | OpenAIFunctionsAgentOutputParser() | route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b2dcb4b2-0e0d-425b-bff8-db7cd33afa16",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'latitude': 37.763283, 'longitude': -122.41286, 'generationtime_ms': 0.02396106719970703, 'utc_offset_seconds': 0, 'timezone': 'GMT', 'timezone_abbreviation': 'GMT', 'elevation': 18.0, 'hourly_units': {'time': 'iso8601', 'temperature_2m': '°C'}, 'hourly': {'time': ['2025-08-09T00:00', '2025-08-09T01:00', '2025-08-09T02:00', '2025-08-09T03:00', '2025-08-09T04:00', '2025-08-09T05:00', '2025-08-09T06:00', '2025-08-09T07:00', '2025-08-09T08:00', '2025-08-09T09:00', '2025-08-09T10:00', '2025-08-09T11:00', '2025-08-09T12:00', '2025-08-09T13:00', '2025-08-09T14:00', '2025-08-09T15:00', '2025-08-09T16:00', '2025-08-09T17:00', '2025-08-09T18:00', '2025-08-09T19:00', '2025-08-09T20:00', '2025-08-09T21:00', '2025-08-09T22:00', '2025-08-09T23:00'], 'temperature_2m': [23.7, 21.9, 18.2, 16.3, 15.0, 14.8, 14.6, 14.3, 13.9, 13.9, 13.6, 13.3, 13.6, 13.5, 13.6, 14.5, 15.1, 16.7, 18.2, 22.5, 22.7, 22.0, 21.6, 20.9]}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The current temperature is 18.2°C'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = chain.invoke({\"input\": \"What is the weather in san francisco right now?\"})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6c93eb1b-044f-4c52-bcd4-dcd0e01f42e8",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Page: LangChain\\nSummary: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain\\'s use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\\n\\nPage: Vector database\\nSummary: A vector database, vector store or vector search engine is a database that uses the vector space model to store vectors (fixed-length lists of numbers) along with other data items. Vector databases typically implement one or more approximate nearest neighbor algorithms, so that one can search the database with a query vector to retrieve the closest matching database records.\\nVectors are mathematical representations of data in a high-dimensional space. In this space, each dimension corresponds to a feature of the data, with the number of dimensions ranging from a few hundred to tens of thousands, depending on the complexity of the data being represented. A vector\\'s position in this space represents its characteristics. Words, phrases, or entire documents, as well as images, audio, and other types of data, can all be vectorized.\\nThese feature vectors may be computed from the raw data using machine learning methods such as feature extraction algorithms, word embeddings or deep learning networks. The goal is that semantically similar data items receive feature vectors close to each other.\\nVector databases can be used for similarity search, semantic search, multi-modal search, recommendations engines, large language models (LLMs), object detection,  etc.\\nVector databases are also often used to implement retrieval-augmented generation (RAG), a method to improve domain-specific responses of large language models. The retrieval component of a RAG can be any search system, but is most often implemented as a vector database. Text documents describing the domain of interest are collected, and for each document or document section, a feature vector (known as an \"embedding\") is computed, typically using a deep learning network, and stored in a vector database. Given a user prompt, the feature vector of the prompt is computed, and the database is queried to retrieve the most relevant documents. These are then automatically added into the context window of the large language model, and the large language model proceeds to create a response to the prompt given this context.\\n\\nPage: Model Context Protocol\\nSummary: The Model Context Protocol (MCP) is an open standard, open-source framework introduced by Anthropic in November 2024 to standardize the way artificial intelligence (AI) systems like large language models (LLMs) integrate and share data with external tools, systems, and data sources. MCP provides a universal interface for reading files, executing functions, and handling contextual prompts. Following its announcement, the protocol was adopted by major AI providers, including OpenAI and Google DeepMind.'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"What is langchain?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a353363e-27b8-440f-a8b7-31bc2e861a42",
   "metadata": {
    "height": 30
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Well, hello there! How can I assist you today?'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"hi!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1570d2-6215-4f24-802d-14e75db4319a",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1bf47c-a050-47ab-a840-b3a67e2b69cc",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2124caf-4362-4608-996d-5cdff95551d7",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6ca0db-6b1d-4d8e-8c63-3a485607fbd9",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0ed82c-8e26-44b3-a1ea-67143ab65161",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9b8542-7719-412c-b240-958ea8bdbbef",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83233f7c-3820-4697-80a6-c25423cc7b26",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a950c46-1a8c-4807-9cc4-373264aaa9dc",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11cf095-9583-4206-8155-2a9acd5a4aad",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181b3737-eb4d-452a-b018-a1289f7f0d41",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
